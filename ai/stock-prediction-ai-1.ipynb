{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albercej/zrh/blob/main/ai/stock-prediction-ai-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install loguru\n",
        "!pip install yahoo_fin\n",
        "#!pip install yfinance"
      ],
      "metadata": {
        "id": "lK-Z48DTJBui",
        "outputId": "f9a8e53c-fda6-4d8c-c960-f2dfadead71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "lK-Z48DTJBui",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yahoo_fin\n",
            "  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (1.3.5)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2.10)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting w3lib\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n",
            "Building wheels for collected packages: fake-useragent, parse, sgmllib3k\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=edf522869961ca0032b27d43fe47d8d135fde621652626720e4fa73a047fbce1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=73e69599d8f25c535e3b398a146e131ba54cab9312042b704bb1a308f9ac9ad2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=c574afcfafad102a6ddc7a20d402d48558532e79b676b272607b842ab17f5f7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built fake-useragent parse sgmllib3k\n",
            "Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, sgmllib3k, pyquery, pyppeteer, parse, fake-useragent, requests-html, feedparser, yahoo-fin\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.8 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 urllib3-1.25.11 w3lib-1.22.0 websockets-10.3 yahoo-fin-0.8.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "055c90a8",
      "metadata": {
        "id": "055c90a8"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from loguru import logger\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Hide warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "US_BUSINESS_DAY = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
        "from yahoo_fin import stock_info as si"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0fc04e12",
      "metadata": {
        "id": "0fc04e12"
      },
      "outputs": [],
      "source": [
        "def get_biz_days_delta_date(start_date_str, delta_days):\n",
        "    start_date = datetime.datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
        "    end_date = start_date + (delta_days * US_BUSINESS_DAY)\n",
        "    end_date_str = datetime.datetime.strftime(end_date, \"%Y-%m-%d\")\n",
        "    return end_date_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "600fc84b",
      "metadata": {
        "id": "600fc84b"
      },
      "outputs": [],
      "source": [
        "def load_price_data(symbol, start_date_str, end_date_str):\n",
        "    # Download data\n",
        "    try:\n",
        "        df = si.get_data(symbol, start_date=start_date_str, end_date=end_date_str, index_as_date=False)\n",
        "        return df\n",
        "    except:\n",
        "        print('Error loading stock data for ' + symbol)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4e669b1c",
      "metadata": {
        "id": "4e669b1c"
      },
      "outputs": [],
      "source": [
        "def cleanup_daily_file(df):\n",
        "    #  Select columns\n",
        "    df.dropna(inplace=True)\n",
        "    df.drop(\"close\", axis=1, inplace=True)\n",
        "    df.drop(\"volume\", axis=1, inplace=True)\n",
        "    df.drop(\"ticker\", axis=1, inplace=True)\n",
        "    df.reset_index(inplace=True)\n",
        "    #  Rearrange column order\n",
        "    df.drop(\"index\", axis=1, inplace=True)\n",
        "    df = df[['adjclose', 'date']]  # , 'open','high','low',\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9507f1ae",
      "metadata": {
        "id": "9507f1ae"
      },
      "outputs": [],
      "source": [
        "def get_train_test_range(df, start_date_str, target_date_str):\n",
        "    query = f\"(date >= '{start_date_str}') and (date <= '{target_date_str}')\"\n",
        "    train_test_df = df.query(query).copy()\n",
        "    return train_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6ea58eeb",
      "metadata": {
        "id": "6ea58eeb"
      },
      "outputs": [],
      "source": [
        "def get_display_range(df, start_date_str, target_date_str, forecast_steps):\n",
        "    #  Get full date range\n",
        "    full_range_date_str = get_biz_days_delta_date(target_date_str, forecast_steps )\n",
        "    query = f\"(date >= '{start_date_str}') and (date <= '{full_range_date_str}')\"\n",
        "    full_date_range_df = df.query(query).copy()\n",
        "    return full_date_range_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2bf9e3ac",
      "metadata": {
        "id": "2bf9e3ac"
      },
      "outputs": [],
      "source": [
        "def train_test_split(df, start_date_str, test_date_str, target_date_str):\n",
        "    train_query = f\"(date >= '{start_date_str}') and (date < '{test_date_str}')\"\n",
        "    train_df = df.query(train_query).copy()\n",
        "    train_df = train_df.set_index('date')\n",
        "\n",
        "    test_query = f\"(date >= '{test_date_str}') and (date <= '{target_date_str}')\"\n",
        "    test_df = df.query(test_query).copy()\n",
        "    test_df = test_df.set_index('date')\n",
        "\n",
        "    return train_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2dd706ca",
      "metadata": {
        "id": "2dd706ca"
      },
      "outputs": [],
      "source": [
        "def scale_data(train_df, test_df, time_steps):\n",
        "    full_scalar = MinMaxScaler(feature_range=(0, 1))\n",
        "    full_df = pd.concat((train_df, test_df), axis=0, ignore_index=True)\n",
        "    full_df_scaled = full_scalar.fit_transform(full_df)\n",
        "\n",
        "    train_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    train_df_scaled = train_scaler.fit_transform(train_df)\n",
        "\n",
        "    test_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    test_df_range = full_df[len(full_df) - len(test_df) - time_steps:]\n",
        "    test_df_scaled = test_scaler.fit_transform(test_df_range)\n",
        "\n",
        "    return full_scalar, train_df_scaled, test_df_scaled, full_df_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "cbe98398",
      "metadata": {
        "id": "cbe98398"
      },
      "outputs": [],
      "source": [
        "def create_X_ys(df_scaled, time_steps, forecast_steps):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(time_steps, df_scaled.shape[0] - forecast_steps + 1):\n",
        "        X.append(df_scaled[i - time_steps:i])\n",
        "        y.append(df_scaled[i:i + forecast_steps])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2]))\n",
        "    y = np.reshape(y, (y.shape[0], y.shape[1] * y.shape[2]))\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0713036d",
      "metadata": {
        "id": "0713036d"
      },
      "outputs": [],
      "source": [
        "def create_X(df_scaled, time_steps):\n",
        "    X = []\n",
        "\n",
        "    for i in range(time_steps, df_scaled.shape[0] + 1):\n",
        "        X.append(df_scaled[i - time_steps:i])\n",
        "\n",
        "    X = np.array(X)\n",
        "\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2]))\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4543e09d",
      "metadata": {
        "id": "4543e09d"
      },
      "outputs": [],
      "source": [
        "def build_model( time_steps, n_forecast_steps, n_features):\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1st layer with Dropout regularisation\n",
        "    # * units = add x neurons is the dimensionality of the output space\n",
        "    # * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "    # * input_shape => Shape of the training dataset\n",
        "    input_shape = (time_steps, n_features)\n",
        "    model.add(LSTM(units=800, return_sequences=True, input_shape=input_shape))\n",
        "    # x% of the layers will be dropped\n",
        "    model.add(Dropout(0.5))\n",
        "    # 2nd LSTM layer\n",
        "    # * units = add x neurons is the dimensionality of the output space\n",
        "    # * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "    model.add(LSTM(units=400, return_sequences=True))\n",
        "    # x% of the layers will be dropped\n",
        "    model.add(Dropout(0.5))\n",
        "    # 3rd LSTM layer\n",
        "    # * units = add x neurons is the dimensionality of the output space\n",
        "    # * return_sequences = True to stack LSTM layers so the next LSTM layer has a three-dimensional sequence input\n",
        "    model.add(LSTM(units=400, return_sequences=True))\n",
        "    # x% of the layers will be dropped\n",
        "    model.add(Dropout(0.5))\n",
        "    # 4th LSTM layer\n",
        "    # * units = add x neurons is the dimensionality of the output space\n",
        "    model.add(LSTM(units=400))\n",
        "    # 50% of the layers will be dropped\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Dense layer that specifies an output of one unit\n",
        "    model.add(Dense(units=n_forecast_steps))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a8e46f87",
      "metadata": {
        "id": "a8e46f87"
      },
      "outputs": [],
      "source": [
        "def train_model(model, X_train, y_train, X_test, y_test, epochs, batch_size, patience):\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, mode='min', verbose=1)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.MeanSquaredError(name='MSE')])\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[early_stop])\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d11cf9cf",
      "metadata": {
        "id": "d11cf9cf"
      },
      "outputs": [],
      "source": [
        "def create_predictions(model, X_full):\n",
        "    full_pred_y = model.predict(X_full)\n",
        "    return full_pred_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "08d98c76",
      "metadata": {
        "id": "08d98c76"
      },
      "outputs": [],
      "source": [
        "def inverse_scale(full_scalar, full_pred_y):\n",
        "    full_pred_y_norm = full_scalar.inverse_transform(full_pred_y)\n",
        "    full_pred_y_norm = pd.DataFrame(full_pred_y_norm)\n",
        "\n",
        "    return full_pred_y_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0084de57",
      "metadata": {
        "id": "0084de57"
      },
      "outputs": [],
      "source": [
        "def create_future_predictions(pred_y_norm, time_steps):\n",
        "    future_predict = pred_y_norm.iloc[-1, 0:time_steps]\n",
        "\n",
        "    future_df = pd.DataFrame(future_predict.values, columns=['adjclose'])\n",
        "\n",
        "    return future_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0bacb937",
      "metadata": {
        "id": "0bacb937"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(symbol, target_date_str, actual_df, pred_y_norm, future_df):\n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.plot(actual_df['adjclose'], color='blue', label='Actual', linewidth=0.8)\n",
        "\n",
        "    plt.plot(pred_y_norm[0], color='green', label='Predicted', linewidth=0.8)\n",
        "\n",
        "    plt.plot(future_df['adjclose'], color='red', label='Future', linewidth=0.8)\n",
        "\n",
        "    plt.axvline(x=len(pred_y_norm), color='r', linewidth=0.4)\n",
        "    plt.axvline(x=len(actual_df) - 20, color='r', linewidth=0.4)\n",
        "\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.title('Prediction')\n",
        "\n",
        "    #  Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fe17e4dc",
      "metadata": {
        "id": "fe17e4dc"
      },
      "outputs": [],
      "source": [
        "def run(cfg):\n",
        "    symbol = cfg[\"symbol\"]\n",
        "    total_days = cfg[\"total_days\"]\n",
        "    target_date_str = cfg[\"target_date_str\"]\n",
        "    split_ratio = cfg[\"split_ratio\"]\n",
        "    time_steps = cfg[\"time_steps\"]\n",
        "    forecast_steps = cfg[\"forecast_steps\"]\n",
        "    target_date_str = cfg[\"target_date_str\"]\n",
        "    batch_size = cfg[\"batch_size\"]\n",
        "    epochs = cfg[\"epochs\"]\n",
        "    patience = cfg[\"patience\"]\n",
        "    n_features = 1\n",
        "    \n",
        "    today = datetime.date.today()\n",
        "    today_str = today.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "    df = load_price_data(symbol, None, today_str)\n",
        "    df = cleanup_daily_file(df)\n",
        "\n",
        "    #  calculate start date\n",
        "    start_date_str = get_biz_days_delta_date(target_date_str, -total_days)\n",
        "  \n",
        "    train_test_df = get_train_test_range(df, start_date_str, target_date_str)\n",
        "    display_df = get_display_range(df, start_date_str, target_date_str, forecast_steps)\n",
        "   \n",
        "    #  Calculate test days\n",
        "    test_days = int(total_days * split_ratio)\n",
        "    test_date_str = get_biz_days_delta_date(target_date_str, -test_days)\n",
        "\n",
        "    train_df, test_df = train_test_split(train_test_df, start_date_str, test_date_str, target_date_str)\n",
        "\n",
        "    full_scalar, train_df_scaled, test_df_scaled, full_df_scaled = scale_data(train_df, test_df, time_steps)\n",
        "\n",
        "    #  Create X's and y's\n",
        "    X_train, y_train = create_X_ys(train_df_scaled, time_steps, forecast_steps)\n",
        "    X_test, y_test = create_X_ys(test_df_scaled, time_steps, forecast_steps)\n",
        "    X_full = create_X(full_df_scaled, time_steps)\n",
        "\n",
        "    print('Building model')\n",
        "    model = build_model(time_steps, forecast_steps, n_features)\n",
        "    print(model.summary())\n",
        "    \n",
        "\n",
        "    train_model(model, X_train, y_train, X_test, y_test, epochs, batch_size, patience)\n",
        "\n",
        "    #  Create predictions\n",
        "    full_pred_y = create_predictions(model, X_full)\n",
        "    full_pred_y_norm = inverse_scale(full_scalar, full_pred_y)\n",
        "\n",
        "    #  Concat train and test predictions\n",
        "    full_pred_y_norm.index += time_steps - 1\n",
        "\n",
        "    train_test_df_display = train_test_df.copy()\n",
        "    train_test_df_display.drop('date', axis=1, inplace=True)\n",
        "    train_test_df_display.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    future_df = create_future_predictions(full_pred_y_norm, time_steps)\n",
        "    future_df.index += len(train_test_df_display) - 2\n",
        "\n",
        "    full_display_df = display_df.copy()\n",
        "    full_display_df.drop('date', axis=1, inplace=True)\n",
        "    full_display_df.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    plot_predictions(symbol, target_date_str, full_display_df, full_pred_y_norm, future_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3264d7c8",
      "metadata": {
        "id": "3264d7c8"
      },
      "outputs": [],
      "source": [
        "#  Base configuration\n",
        "cfg = {\"symbol\": \"TSLA\",\n",
        "       \"target_date_str\": '2021-12-01',\n",
        "       \"total_days\": 600,\n",
        "       \"split_ratio\": 0.2,\n",
        "       \"epochs\": 300,\n",
        "       \"batch_size\": 32,\n",
        "       \"time_steps\": 30,\n",
        "       \"forecast_steps\": 10,\n",
        "       \"patience\": 50}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "83a9143f",
      "metadata": {
        "id": "83a9143f",
        "outputId": "e25dcca1-7334-4bb5-a528-8391754eb7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing AAPL\n",
            "Building model\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 30, 800)           2566400   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 800)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 30, 400)           1921600   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30, 400)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 30, 400)           1281600   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 30, 400)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 400)               1281600   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                4010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,055,210\n",
            "Trainable params: 7,055,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/300\n",
            "14/14 [==============================] - 35s 2s/step - loss: 0.1913 - MSE: 0.1913 - val_loss: 0.0847 - val_MSE: 0.0847\n",
            "Epoch 2/300\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.0408 - MSE: 0.0408 - val_loss: 0.0443 - val_MSE: 0.0443\n",
            "Epoch 3/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0219 - MSE: 0.0219 - val_loss: 0.0241 - val_MSE: 0.0241\n",
            "Epoch 4/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0174 - MSE: 0.0174 - val_loss: 0.0288 - val_MSE: 0.0288\n",
            "Epoch 5/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0141 - MSE: 0.0141 - val_loss: 0.0229 - val_MSE: 0.0229\n",
            "Epoch 6/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0136 - MSE: 0.0136 - val_loss: 0.0275 - val_MSE: 0.0275\n",
            "Epoch 7/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0127 - MSE: 0.0127 - val_loss: 0.0236 - val_MSE: 0.0236\n",
            "Epoch 8/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0126 - MSE: 0.0126 - val_loss: 0.0218 - val_MSE: 0.0218\n",
            "Epoch 9/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0121 - MSE: 0.0121 - val_loss: 0.0226 - val_MSE: 0.0226\n",
            "Epoch 10/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0123 - MSE: 0.0123 - val_loss: 0.0222 - val_MSE: 0.0222\n",
            "Epoch 11/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0140 - MSE: 0.0140 - val_loss: 0.0203 - val_MSE: 0.0203\n",
            "Epoch 12/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0149 - MSE: 0.0149 - val_loss: 0.0232 - val_MSE: 0.0232\n",
            "Epoch 13/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0124 - MSE: 0.0124 - val_loss: 0.0213 - val_MSE: 0.0213\n",
            "Epoch 14/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0104 - MSE: 0.0104 - val_loss: 0.0193 - val_MSE: 0.0193\n",
            "Epoch 15/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0106 - MSE: 0.0106 - val_loss: 0.0198 - val_MSE: 0.0198\n",
            "Epoch 16/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0100 - MSE: 0.0100 - val_loss: 0.0182 - val_MSE: 0.0182\n",
            "Epoch 17/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0097 - MSE: 0.0097 - val_loss: 0.0195 - val_MSE: 0.0195\n",
            "Epoch 18/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0137 - MSE: 0.0137 - val_loss: 0.0212 - val_MSE: 0.0212\n",
            "Epoch 19/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0099 - MSE: 0.0099 - val_loss: 0.0191 - val_MSE: 0.0191\n",
            "Epoch 20/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0094 - MSE: 0.0094 - val_loss: 0.0156 - val_MSE: 0.0156\n",
            "Epoch 21/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0094 - MSE: 0.0094 - val_loss: 0.0188 - val_MSE: 0.0188\n",
            "Epoch 22/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0091 - MSE: 0.0091 - val_loss: 0.0173 - val_MSE: 0.0173\n",
            "Epoch 23/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0166 - val_MSE: 0.0166\n",
            "Epoch 24/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0080 - MSE: 0.0080 - val_loss: 0.0153 - val_MSE: 0.0153\n",
            "Epoch 25/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0169 - val_MSE: 0.0169\n",
            "Epoch 26/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0088 - MSE: 0.0088 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 27/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0143 - val_MSE: 0.0143\n",
            "Epoch 28/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0134 - val_MSE: 0.0134\n",
            "Epoch 29/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0078 - MSE: 0.0078 - val_loss: 0.0147 - val_MSE: 0.0147\n",
            "Epoch 30/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0077 - MSE: 0.0077 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 31/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0134 - val_MSE: 0.0134\n",
            "Epoch 32/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0128 - val_MSE: 0.0128\n",
            "Epoch 33/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0070 - MSE: 0.0070 - val_loss: 0.0136 - val_MSE: 0.0136\n",
            "Epoch 34/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0127 - val_MSE: 0.0127\n",
            "Epoch 35/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 36/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0072 - MSE: 0.0072 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 37/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0070 - MSE: 0.0070 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 38/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0067 - MSE: 0.0067 - val_loss: 0.0155 - val_MSE: 0.0155\n",
            "Epoch 39/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0071 - MSE: 0.0071 - val_loss: 0.0151 - val_MSE: 0.0151\n",
            "Epoch 40/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0073 - MSE: 0.0073 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 41/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0064 - MSE: 0.0064 - val_loss: 0.0118 - val_MSE: 0.0118\n",
            "Epoch 42/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0063 - MSE: 0.0063 - val_loss: 0.0161 - val_MSE: 0.0161\n",
            "Epoch 43/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0076 - MSE: 0.0076 - val_loss: 0.0154 - val_MSE: 0.0154\n",
            "Epoch 44/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0074 - MSE: 0.0074 - val_loss: 0.0158 - val_MSE: 0.0158\n",
            "Epoch 45/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0066 - MSE: 0.0066 - val_loss: 0.0131 - val_MSE: 0.0131\n",
            "Epoch 46/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0058 - MSE: 0.0058 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 47/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0059 - MSE: 0.0059 - val_loss: 0.0122 - val_MSE: 0.0122\n",
            "Epoch 48/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0063 - MSE: 0.0063 - val_loss: 0.0132 - val_MSE: 0.0132\n",
            "Epoch 49/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0065 - MSE: 0.0065 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 50/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0060 - MSE: 0.0060 - val_loss: 0.0129 - val_MSE: 0.0129\n",
            "Epoch 51/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0056 - MSE: 0.0056 - val_loss: 0.0129 - val_MSE: 0.0129\n",
            "Epoch 52/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 53/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0174 - val_MSE: 0.0174\n",
            "Epoch 54/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0062 - MSE: 0.0062 - val_loss: 0.0149 - val_MSE: 0.0149\n",
            "Epoch 55/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0054 - MSE: 0.0054 - val_loss: 0.0146 - val_MSE: 0.0146\n",
            "Epoch 56/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0054 - MSE: 0.0054 - val_loss: 0.0155 - val_MSE: 0.0155\n",
            "Epoch 57/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0060 - MSE: 0.0060 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 58/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0051 - MSE: 0.0051 - val_loss: 0.0147 - val_MSE: 0.0147\n",
            "Epoch 59/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0052 - MSE: 0.0052 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 60/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0148 - val_MSE: 0.0148\n",
            "Epoch 61/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0124 - val_MSE: 0.0124\n",
            "Epoch 62/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0047 - MSE: 0.0047 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 63/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0051 - MSE: 0.0051 - val_loss: 0.0117 - val_MSE: 0.0117\n",
            "Epoch 64/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0056 - MSE: 0.0056 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 65/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0051 - MSE: 0.0051 - val_loss: 0.0119 - val_MSE: 0.0119\n",
            "Epoch 66/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0128 - val_MSE: 0.0128\n",
            "Epoch 67/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0055 - MSE: 0.0055 - val_loss: 0.0162 - val_MSE: 0.0162\n",
            "Epoch 68/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0054 - MSE: 0.0054 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 69/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0046 - MSE: 0.0046 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 70/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0051 - MSE: 0.0051 - val_loss: 0.0134 - val_MSE: 0.0134\n",
            "Epoch 71/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0053 - MSE: 0.0053 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 72/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0047 - MSE: 0.0047 - val_loss: 0.0141 - val_MSE: 0.0141\n",
            "Epoch 73/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0132 - val_MSE: 0.0132\n",
            "Epoch 74/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0050 - MSE: 0.0050 - val_loss: 0.0160 - val_MSE: 0.0160\n",
            "Epoch 75/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0055 - MSE: 0.0055 - val_loss: 0.0129 - val_MSE: 0.0129\n",
            "Epoch 76/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0056 - MSE: 0.0056 - val_loss: 0.0136 - val_MSE: 0.0136\n",
            "Epoch 77/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0136 - val_MSE: 0.0136\n",
            "Epoch 78/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0049 - MSE: 0.0049 - val_loss: 0.0132 - val_MSE: 0.0132\n",
            "Epoch 79/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0046 - MSE: 0.0046 - val_loss: 0.0118 - val_MSE: 0.0118\n",
            "Epoch 80/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0046 - MSE: 0.0046 - val_loss: 0.0122 - val_MSE: 0.0122\n",
            "Epoch 81/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0128 - val_MSE: 0.0128\n",
            "Epoch 82/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0119 - val_MSE: 0.0119\n",
            "Epoch 83/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0047 - MSE: 0.0047 - val_loss: 0.0149 - val_MSE: 0.0149\n",
            "Epoch 84/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0050 - MSE: 0.0050 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 85/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0056 - MSE: 0.0056 - val_loss: 0.0159 - val_MSE: 0.0159\n",
            "Epoch 86/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0119 - val_MSE: 0.0119\n",
            "Epoch 87/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0048 - MSE: 0.0048 - val_loss: 0.0149 - val_MSE: 0.0149\n",
            "Epoch 88/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 89/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0128 - val_MSE: 0.0128\n",
            "Epoch 90/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 91/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0047 - MSE: 0.0047 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 92/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 93/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0131 - val_MSE: 0.0131\n",
            "Epoch 94/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 95/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0049 - MSE: 0.0049 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 96/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0046 - MSE: 0.0046 - val_loss: 0.0131 - val_MSE: 0.0131\n",
            "Epoch 97/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 98/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 99/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0141 - val_MSE: 0.0141\n",
            "Epoch 100/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0144 - val_MSE: 0.0144\n",
            "Epoch 101/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0050 - MSE: 0.0050 - val_loss: 0.0133 - val_MSE: 0.0133\n",
            "Epoch 102/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0110 - val_MSE: 0.0110\n",
            "Epoch 103/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 104/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 105/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 106/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 107/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 108/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0052 - MSE: 0.0052 - val_loss: 0.0172 - val_MSE: 0.0172\n",
            "Epoch 109/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 110/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0049 - MSE: 0.0049 - val_loss: 0.0129 - val_MSE: 0.0129\n",
            "Epoch 111/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0124 - val_MSE: 0.0124\n",
            "Epoch 112/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 113/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 114/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0049 - MSE: 0.0049 - val_loss: 0.0167 - val_MSE: 0.0167\n",
            "Epoch 115/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 116/300\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 117/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0140 - val_MSE: 0.0140\n",
            "Epoch 118/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0117 - val_MSE: 0.0117\n",
            "Epoch 119/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 120/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 121/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0128 - val_MSE: 0.0128\n",
            "Epoch 122/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0163 - val_MSE: 0.0163\n",
            "Epoch 123/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0119 - val_MSE: 0.0119\n",
            "Epoch 124/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 125/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0107 - val_MSE: 0.0107\n",
            "Epoch 126/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0143 - val_MSE: 0.0143\n",
            "Epoch 127/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0109 - val_MSE: 0.0109\n",
            "Epoch 128/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0113 - val_MSE: 0.0113\n",
            "Epoch 129/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0120 - val_MSE: 0.0120\n",
            "Epoch 130/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0109 - val_MSE: 0.0109\n",
            "Epoch 131/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0172 - val_MSE: 0.0172\n",
            "Epoch 132/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 133/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 134/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0106 - val_MSE: 0.0106\n",
            "Epoch 135/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 136/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0140 - val_MSE: 0.0140\n",
            "Epoch 137/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 138/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 139/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0120 - val_MSE: 0.0120\n",
            "Epoch 140/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0133 - val_MSE: 0.0133\n",
            "Epoch 141/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 142/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 143/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 144/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 145/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0136 - val_MSE: 0.0136\n",
            "Epoch 146/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0122 - val_MSE: 0.0122\n",
            "Epoch 147/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 148/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0143 - val_MSE: 0.0143\n",
            "Epoch 149/300\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0102 - val_MSE: 0.0102\n",
            "Epoch 150/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0142 - val_MSE: 0.0142\n",
            "Epoch 151/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0140 - val_MSE: 0.0140\n",
            "Epoch 152/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0127 - val_MSE: 0.0127\n",
            "Epoch 153/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 154/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 155/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0144 - val_MSE: 0.0144\n",
            "Epoch 156/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0120 - val_MSE: 0.0120\n",
            "Epoch 157/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0045 - MSE: 0.0045 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 158/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0132 - val_MSE: 0.0132\n",
            "Epoch 159/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0103 - val_MSE: 0.0103\n",
            "Epoch 160/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0152 - val_MSE: 0.0152\n",
            "Epoch 161/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 162/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0107 - val_MSE: 0.0107\n",
            "Epoch 163/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0113 - val_MSE: 0.0113\n",
            "Epoch 164/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0119 - val_MSE: 0.0119\n",
            "Epoch 165/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0134 - val_MSE: 0.0134\n",
            "Epoch 166/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 167/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 168/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 169/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0109 - val_MSE: 0.0109\n",
            "Epoch 170/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 171/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 172/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 173/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 174/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 175/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0110 - val_MSE: 0.0110\n",
            "Epoch 176/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0122 - val_MSE: 0.0122\n",
            "Epoch 177/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 178/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 179/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0151 - val_MSE: 0.0151\n",
            "Epoch 180/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0134 - val_MSE: 0.0134\n",
            "Epoch 181/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 182/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 183/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0124 - val_MSE: 0.0124\n",
            "Epoch 184/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0131 - val_MSE: 0.0131\n",
            "Epoch 185/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 186/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0097 - val_MSE: 0.0097\n",
            "Epoch 187/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0109 - val_MSE: 0.0109\n",
            "Epoch 188/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0155 - val_MSE: 0.0155\n",
            "Epoch 189/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0113 - val_MSE: 0.0113\n",
            "Epoch 190/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0143 - val_MSE: 0.0143\n",
            "Epoch 191/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0122 - val_MSE: 0.0122\n",
            "Epoch 192/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 193/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0041 - MSE: 0.0041 - val_loss: 0.0147 - val_MSE: 0.0147\n",
            "Epoch 194/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0107 - val_MSE: 0.0107\n",
            "Epoch 195/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 196/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0106 - val_MSE: 0.0106\n",
            "Epoch 197/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0113 - val_MSE: 0.0113\n",
            "Epoch 198/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0042 - MSE: 0.0042 - val_loss: 0.0124 - val_MSE: 0.0124\n",
            "Epoch 199/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0124 - val_MSE: 0.0124\n",
            "Epoch 200/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 201/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0103 - val_MSE: 0.0103\n",
            "Epoch 202/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 203/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0111 - val_MSE: 0.0111\n",
            "Epoch 204/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0115 - val_MSE: 0.0115\n",
            "Epoch 205/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0109 - val_MSE: 0.0109\n",
            "Epoch 206/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0100 - val_MSE: 0.0100\n",
            "Epoch 207/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0126 - val_MSE: 0.0126\n",
            "Epoch 208/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0121 - val_MSE: 0.0121\n",
            "Epoch 209/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0136 - val_MSE: 0.0136\n",
            "Epoch 210/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0091 - val_MSE: 0.0091\n",
            "Epoch 211/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0118 - val_MSE: 0.0118\n",
            "Epoch 212/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0140 - val_MSE: 0.0140\n",
            "Epoch 213/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0104 - val_MSE: 0.0104\n",
            "Epoch 214/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0154 - val_MSE: 0.0154\n",
            "Epoch 215/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0098 - val_MSE: 0.0098\n",
            "Epoch 216/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0125 - val_MSE: 0.0125\n",
            "Epoch 217/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 218/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0152 - val_MSE: 0.0152\n",
            "Epoch 219/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0040 - MSE: 0.0040 - val_loss: 0.0103 - val_MSE: 0.0103\n",
            "Epoch 220/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 221/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0099 - val_MSE: 0.0099\n",
            "Epoch 222/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0157 - val_MSE: 0.0157\n",
            "Epoch 223/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 224/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0120 - val_MSE: 0.0120\n",
            "Epoch 225/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 226/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0137 - val_MSE: 0.0137\n",
            "Epoch 227/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0130 - val_MSE: 0.0130\n",
            "Epoch 228/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0031 - MSE: 0.0031 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 229/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0044 - MSE: 0.0044 - val_loss: 0.0187 - val_MSE: 0.0187\n",
            "Epoch 230/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0043 - MSE: 0.0043 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 231/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 232/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0149 - val_MSE: 0.0149\n",
            "Epoch 233/300\n",
            "14/14 [==============================] - 27s 2s/step - loss: 0.0038 - MSE: 0.0038 - val_loss: 0.0116 - val_MSE: 0.0116\n",
            "Epoch 234/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0131 - val_MSE: 0.0131\n",
            "Epoch 235/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0106 - val_MSE: 0.0106\n",
            "Epoch 236/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0118 - val_MSE: 0.0118\n",
            "Epoch 237/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0146 - val_MSE: 0.0146\n",
            "Epoch 238/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0116 - val_MSE: 0.0116\n",
            "Epoch 239/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0036 - MSE: 0.0036 - val_loss: 0.0097 - val_MSE: 0.0097\n",
            "Epoch 240/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0135 - val_MSE: 0.0135\n",
            "Epoch 241/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0107 - val_MSE: 0.0107\n",
            "Epoch 242/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0028 - MSE: 0.0028 - val_loss: 0.0112 - val_MSE: 0.0112\n",
            "Epoch 243/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0107 - val_MSE: 0.0107\n",
            "Epoch 244/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0108 - val_MSE: 0.0108\n",
            "Epoch 245/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0164 - val_MSE: 0.0164\n",
            "Epoch 246/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0030 - MSE: 0.0030 - val_loss: 0.0116 - val_MSE: 0.0116\n",
            "Epoch 247/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0031 - MSE: 0.0031 - val_loss: 0.0097 - val_MSE: 0.0097\n",
            "Epoch 248/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0031 - MSE: 0.0031 - val_loss: 0.0118 - val_MSE: 0.0118\n",
            "Epoch 249/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0039 - MSE: 0.0039 - val_loss: 0.0145 - val_MSE: 0.0145\n",
            "Epoch 250/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0098 - val_MSE: 0.0098\n",
            "Epoch 251/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0037 - MSE: 0.0037 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 252/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0093 - val_MSE: 0.0093\n",
            "Epoch 253/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0123 - val_MSE: 0.0123\n",
            "Epoch 254/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0035 - MSE: 0.0035 - val_loss: 0.0105 - val_MSE: 0.0105\n",
            "Epoch 255/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0034 - MSE: 0.0034 - val_loss: 0.0138 - val_MSE: 0.0138\n",
            "Epoch 256/300\n",
            "14/14 [==============================] - 25s 2s/step - loss: 0.0033 - MSE: 0.0033 - val_loss: 0.0110 - val_MSE: 0.0110\n",
            "Epoch 257/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0133 - val_MSE: 0.0133\n",
            "Epoch 258/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0032 - MSE: 0.0032 - val_loss: 0.0114 - val_MSE: 0.0114\n",
            "Epoch 259/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0031 - MSE: 0.0031 - val_loss: 0.0100 - val_MSE: 0.0100\n",
            "Epoch 260/300\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.0028 - MSE: 0.0028 - val_loss: 0.0133 - val_MSE: 0.0133\n",
            "Epoch 260: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#  Load NASDAQ 100 symbols\n",
        "nasdaq_100_df = pd.read_csv('https://raw.githubusercontent.com/justmobiledev/python-algorithmic-trading/main/data/nasdaq_100.csv')\n",
        "symbols = nasdaq_100_df['Symbol'].to_numpy()\n",
        "\n",
        "#  Run eval for all symbols\n",
        "for symbol in symbols:\n",
        "    global cf\n",
        "    print(f\"Processing {symbol}\")\n",
        "    cfg['symbol'] = symbol\n",
        "    run(cfg)\n",
        "    break\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26601672",
      "metadata": {
        "id": "26601672"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tradesystem1]",
      "language": "python",
      "name": "conda-env-tradesystem1-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "stock-prediction-ai-1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}